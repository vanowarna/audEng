{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOE/W/4F5um5fOJPgqGnR8W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vanowarna/audEng/blob/main/Activity%205/pitch_shifting_torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJOh-yR_va0C",
        "outputId": "34723492-0239-458a-b097-598a5aaa1011"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch-pitch-shift in /usr/local/lib/python3.10/dist-packages (1.2.4)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from torch-pitch-shift) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchaudio>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from torch-pitch-shift) (2.1.0+cu118)\n",
            "Requirement already satisfied: primePy>=1.3 in /usr/local/lib/python3.10/dist-packages (from torch-pitch-shift) (1.3)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from torch-pitch-shift) (23.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torch-pitch-shift) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torch-pitch-shift) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torch-pitch-shift) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torch-pitch-shift) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torch-pitch-shift) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torch-pitch-shift) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torch-pitch-shift) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->torch-pitch-shift) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->torch-pitch-shift) (1.3.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-pitch-shift\n",
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from scipy.io import wavfile\n",
        "# from torch_pitch_shift import *\n",
        "\n",
        "# Define input and output file paths\n",
        "input_audio_path = '/content/drive/Shareddrives/AlgoPirates/vanowarna/audEng/pitch shifting/cropped_perfect_vocal.wav'\n",
        "output_audio_path = '/content/drive/Shareddrives/AlgoPirates/vanowarna/audEng/pitch shifting/output_pitch_shifted_wavelet.wav'\n",
        "\n",
        "# Read an audio file\n",
        "sample_rate, input_waveform = wavfile.read(input_audio_path)\n",
        "\n",
        "# Convert to tensor of shape (batch_size, channels, samples)\n",
        "dtype = input_waveform.dtype\n",
        "input_waveform_tensor = torch.tensor(\n",
        "    [np.swapaxes(input_waveform, 0, 1)],  # (samples, channels) --> (channels, samples)\n",
        "    dtype=torch.float32,\n",
        "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        ")\n",
        "\n",
        "def pitch_shift(\n",
        "    input: torch.Tensor,\n",
        "    shift: Union[float, Fraction],\n",
        "    sample_rate: int,\n",
        "    bins_per_octave: Optional[int] = 12,\n",
        "    n_fft: Optional[int] = 0,\n",
        "    hop_length: Optional[int] = 0,\n",
        ") -> torch.Tensor:\n",
        "\n",
        "    if not n_fft:\n",
        "        n_fft = sample_rate // 64\n",
        "    if not hop_length:\n",
        "        hop_length = n_fft // 32\n",
        "    batch_size, channels, samples = input.shape\n",
        "    if not isinstance(shift, Fraction):\n",
        "        shift = 2.0 ** (float(shift) / bins_per_octave)\n",
        "    resampler = T.Resample(sample_rate, int(sample_rate / shift)).to(input.device)\n",
        "    output = input\n",
        "    output = output.reshape(batch_size * channels, samples)\n",
        "    v011 = version.parse(torchaudio.__version__) >= version.parse(\"0.11.0\")\n",
        "    output = torch.stft(output, n_fft, hop_length, return_complex=v011)[None, ...]\n",
        "    stretcher = T.TimeStretch(\n",
        "        fixed_rate=float(1 / shift), n_freq=output.shape[2], hop_length=hop_length\n",
        "    ).to(input.device)\n",
        "    output = stretcher(output)\n",
        "    output = torch.istft(output[0], n_fft, hop_length)\n",
        "    output = resampler(output)\n",
        "    del resampler, stretcher\n",
        "    if output.shape[1] >= input.shape[2]:\n",
        "        output = output[:, : (input.shape[2])]\n",
        "    else:\n",
        "        output = pad(output, pad=(0, input.shape[2] - output.shape[1], 0, 0))\n",
        "\n",
        "    output = output.reshape(batch_size, channels, samples)\n",
        "    return output\n",
        "\n",
        "def test_pitch_shift_12_up():\n",
        "    # Pitch up by 12 semitones\n",
        "    shifted_up = pitch_shift(input_waveform_tensor, 12, sample_rate)\n",
        "    assert shifted_up.shape == input_waveform_tensor.shape\n",
        "    wavfile.write(\n",
        "        output_audio_path + 'shifted_octave_+1.wav',\n",
        "        sample_rate,\n",
        "        np.swapaxes(shifted_up.cpu()[0].numpy(), 0, 1).astype(dtype),\n",
        "    )\n",
        "\n",
        "def test_pitch_shift_12_down():\n",
        "    # Pitch down by 12 semitones\n",
        "    shifted_down = pitch_shift(input_waveform_tensor, -12, sample_rate)\n",
        "    assert shifted_down.shape == input_waveform_tensor.shape\n",
        "    wavfile.write(\n",
        "        output_audio_path + 'shifted_octave_-1.wav',\n",
        "        sample_rate,\n",
        "        np.swapaxes(shifted_down.cpu()[0].numpy(), 0, 1).astype(dtype),\n",
        "    )"
      ],
      "metadata": {
        "id": "eqiZtfOUwgwG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pitch_shift_12_up()\n",
        "test_pitch_shift_12_down()"
      ],
      "metadata": {
        "id": "ySoIwHduxYx7"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}